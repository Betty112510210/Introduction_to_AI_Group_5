# -*- coding: utf-8 -*-
"""youtube_api_scratch

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1egSPEO96C6T7Q8HUh4wB4IBlbflRafaw

時間排序
"""
"""減少雜訊版本，前200則"""

!pip install google-api-python-client langdetect emoji

from googleapiclient.discovery import build
from langdetect import detect
import csv
import time
import re

# YouTube API 設定
api_key = 'your_api_key'  # ← 請換成你的 API
video_id = 'your_youtube_ID'
youtube = build('youtube', 'v3', developerKey=api_key)

# 處理留言內容：去除 <br> 與換行，但保留 emoji
def clean_comment(text):
    text = text.replace('<br>', ' ')
    text = text.replace('\n', ' ')
    return text.strip()

# 判斷是否為英文（保留 emoji，不刪除）
def is_english(text):
    try:
        # 只剔除換行標籤，保留 emoji 再判斷語言
        temp = clean_comment(text)
        return detect(temp) == 'en'
    except:
        return False

# 抓最多 200 則英文留言與回覆（保留 emoji）
def get_top_related_comments(video_id, max_results=200):
    results = []
    next_page_token = None

    while len(results) < max_results:
        response = youtube.commentThreads().list(
            part='snippet,replies',
            videoId=video_id,
            maxResults=100,
            order='relevance',
            textFormat='plainText',
            pageToken=next_page_token
        ).execute()

        for item in response['items']:
            # 主留言
            comment = item['snippet']['topLevelComment']['snippet']
            author = comment.get('authorDisplayName', '')
            text = comment['textDisplay']
            published_at = comment['publishedAt']

            if is_english(text):
                cleaned = clean_comment(text)
                results.append([author, cleaned, published_at, False])

            # 回覆
            if 'replies' in item:
                for reply in item['replies']['comments']:
                    r = reply['snippet']
                    reply_text = r['textDisplay']
                    reply_author = r.get('authorDisplayName', '')
                    reply_time = r['publishedAt']

                    if is_english(reply_text):
                        cleaned_reply = clean_comment(reply_text)
                        results.append([reply_author, cleaned_reply, reply_time, True])

            if len(results) >= max_results:
                break

        if len(results) >= max_results or 'nextPageToken' not in response:
            break

        next_page_token = response.get('nextPageToken')
        time.sleep(0.5)

    return results[:max_results]

# 取得資料
comments_data = get_top_related_comments(video_id, max_results=200)

# 存成 CSV（Colab 使用者可搭配下載）
filename = 'top_200_english_with_emoji.csv'
with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.writer(f)
    writer.writerow(['Author', 'Comment', 'PublishedAt', 'IsReply'])
    writer.writerows(comments_data)

print(f'✔ 已儲存 {len(comments_data)} 則留言至 {filename}')
