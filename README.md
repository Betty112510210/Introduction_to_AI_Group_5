# Youtube Comments Sentiment Analysis

Emotion Analysis Using LLMs model

## Project Description

Cyberbullying has become an unignorable issue with the rise of the internet, contributing to mental health problems, social hostility, and even retaliatory behavior. In addition to native speakers, language learners often misuse words when expressing their opinions, which can lead to misunderstandings or unintentionally harmful comments. Our model is designed to analyze YouTube user comments to determine whether they are emotionally charged or potentially abusive. It provides feedback and sentiment scores for comments before they are posted. The project collect data using the YouTube API and manual labeling, identifying harmful comments through classification, analysis, and deep learning techniques. Each comment is assigned a sentiment score ranging from -1 to 1, where lower scores indicate more negative or aggressive content. This tool is especially helpful for non-native English speakers to revise and improve their comments before sharing them online.

This project analyzes YouTube comments using sentiment analysis and cyberbullying detection models, collecting over 6,000 YouTube comments as the raw dataset. Using a large language model (GPT-4o, which yielded the most consistent performance in our tests), we labeled comments into three sentiment categories: **negative, neutral, and positive.** A total of 3,000 comments, 1,000 from each category, were then selected to train our sentiment analysis model.

To evaluate labeling strategies, we tested multiple prompting approaches by manually labelling 100 sample comments for comparison:

- Direct sentiment classification
- Contextual framing for cyberbullying detection
- Contextual framing for hate speech detection

## Getting Started

### Step1: Youtube Comments Fetching

### ğŸ“¦ Prerequisites
Please make sure you have the following:

- Python 3.8 or above
- pip (Python package manager)
- Install required packages:

 ```python
pip install google-api-python-client langdetect emoji
 ```

### ğŸ”‘ API Setup
- Go to Google Cloud Console, create a project and enable YouTube Data API v3.
- Generate an API key.
- Store the key securely (e.g., in an environment variable or config file. **Do not hardcode your key directly into public scripts.**)

### ğŸ“„ Usage: YouTube Comment Scraper
Use the script below to retrieve up to 200 English YouTube comments and replies with emoji retained:

 ```python

from googleapiclient.discovery import build
from langdetect import detect
import csv
import time

api_key = 'YOUR_YOUTUBE_API_KEY' # Replace with your API key and target video ID
video_id = 'YOUR_VIDEO_ID' # You could find it in the website of the video
youtube = build('youtube', 'v3', developerKey=api_key)

def clean_comment(text): # clear irrelevent space but keep the emoji.
    text = text.replace('<br>', ' ')
    text = text.replace('\n', ' ')
    return text.strip()

def is_english(text): # scratch only English comments for better annalysis.
    try:
        temp = clean_comment(text)
        return detect(temp) == 'en'
    except:
        return False

def get_top_related_comments(video_id, max_results=200): #scratch only 200 comments per video for diverse dataset
    results = []
    next_page_token = None

    while len(results) < max_results:
        response = youtube.commentThreads().list(
            part='snippet,replies',
            videoId=video_id,
            maxResults=100,
            order='relevance',
            textFormat='plainText',
            pageToken=next_page_token
        ).execute()

        for item in response['items']: # main comments
            comment = item['snippet']['topLevelComment']['snippet']
            author = comment.get('authorDisplayName', '')
            text = comment['textDisplay']
            published_at = comment['publishedAt']

            if is_english(text):
                cleaned = clean_comment(text)
                results.append([author, cleaned, published_at, False])

            if 'replies' in item: # reply comments
                for reply in item['replies']['comments']:
                    r = reply['snippet']
                    reply_text = r['textDisplay']
                    reply_author = r.get('authorDisplayName', '')
                    reply_time = r['publishedAt']

                    if is_english(reply_text):
                        cleaned_reply = clean_comment(reply_text)
                        results.append([reply_author, cleaned_reply, reply_time, True])

            if len(results) >= max_results:
                break

        if len(results) >= max_results or 'nextPageToken' not in response:
            break

        next_page_token = response.get('nextPageToken')
        time.sleep(0.5)

    return results[:max_results]

comments_data = get_top_related_comments(video_id, max_results=200)

filename = 'top_200_english_with_emoji.csv'
with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.writer(f)
    writer.writerow(['Author', 'Comment', 'PublishedAt', 'IsReply'])
    writer.writerows(comments_data)

print(f'âœ” Saved {len(comments_data)} comments to {filename}')
 ```
### ğŸ“‚ Output
The output is a CSV file containing:

- Author: Commenter's name
- Comment: Cleaned text (emoji preserved)
- PublishedAt: Timestamp
- IsReply: Whether the comment is a reply

### Step2: Comments Sentiment Label with API

### ğŸ“¦ Prerequisites
Please make sure the following packages are installed in your environment:
 ```python
pip install openai pandas tqdm
 ```
This script is designed to run on Google Colab or local environments with access to OpenAI API and CSV-based comment data.

### ğŸ”‘ API Setup
Sign up for access to the OpenAI API at https://platform.openai.com

Generate your secret API key

Replace the following line in your script with your own key (do not upload your key to public repositories):
 ```python
client = OpenAI(api_key="your-api-key")
 ```

### ğŸ§  Prompt Engineering
To evaluate the labeling quality of GPT-4o, we designed specialized prompts for different tasks. Rather than relying on minimal instructions, each prompt embeds context, definitions, and examples to simulate expert human judgment.

1. Sentiment Classification Prompt (Label Accuracy:89%)
Model is asked to classify YouTube comments into **positive, neutral, or negative** with the awareness of internet slang, tone and emoji:
 ```python
prompt= f"""
è«‹åƒè€ƒ YouTube ç•™è¨€èˆ‡ç¶²è·¯æµè¡Œç”¨å­—ï¼Œ
ä½ æ˜¯å°ˆæ¥­çš„ç¶²è·¯è©•è«–åˆ†æå¸«ï¼Œ
åˆ¤æ–·ä»¥ä¸‹ç•™è¨€çš„æƒ…ç·’ï¼Œåªå›è¦†ä¸€å€‹è©ï¼š
positiveã€neutral æˆ– negativeã€‚
ç•™è¨€ï¼š{comment}
"""
 ```

2-1. Hate Speech Detection Prompt (Label Accuracy:65%)
Includes a formal definition of hate speech (based on identity-based attacks and social harm) and asks for binary judgment:
 ```python
prompt= f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç¶²è·¯è©•è«–åˆ†æå¸«ï¼Œç†Ÿæ‚‰ YouTube ç•™è¨€èˆ‡ç¶²è·¯ç”¨èªã€‚

ä»‡æ¨è¨€è«–ï¼ˆHate speechï¼‰çš„å®šç¾©å¦‚ä¸‹ï¼š
ä»‡æ¨è¨€è«–æ˜¯æŒ‡æ”»æ“Šã€è²¶ä½ã€æ­§è¦–æˆ–ç…½å‹•å°ç‰¹å®šå€‹äººæˆ–ç¾¤é«”çš„æ•µæ„è¨€è«–ï¼Œ
ç‰¹åˆ¥æ˜¯é‡å°å…¶ç¨®æ—ã€æ€§åˆ¥ã€å®—æ•™ã€æ€§å–å‘ã€èº«å¿ƒéšœç¤™ã€åœ‹ç±ç­‰èº«ä»½ã€‚
é€™äº›è¨€è«–å¯èƒ½å¸¶æœ‰äººèº«æ”»æ“Šã€æ¿€èµ·ä»‡æ¨ã€ç…½å‹•æš´åŠ›æˆ–ç¤¾æœƒå°ç«‹ï¼Œ
ä¸¦å¯èƒ½å¼•ç™¼é–±è®€è€…çš„è² é¢æƒ…ç·’æˆ–ç¤¾æœƒå½±éŸ¿ã€‚

è«‹ä½ æ ¹æ“šé€™å€‹å®šç¾©ï¼Œåˆ¤æ–·ä¸‹åˆ—ç•™è¨€æ˜¯å¦å±¬æ–¼ä»‡æ¨è¨€è«–ã€‚
è«‹åªå›ç­”ã€Œæœƒã€æˆ–ã€Œä¸æœƒã€ï¼Œä¸è¦è£œå……ä»»ä½•èªªæ˜æˆ–ç†ç”±ã€‚

ç•™è¨€ï¼š
{comment}
"""
 ```

2-2 Hate Speech Detection Prompt without discription (Label Accuracy: 34%)
Model is asked to classify whether YouTube comments invovled hatred speech with the awareness of internet slang, tone and emoji and no context provided: 
 ```python
prompt= f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç¶²è·¯è©•è«–åˆ†æå¸«ï¼Œç†Ÿæ‚‰ YouTube ç•™è¨€èˆ‡ç¶²è·¯ç”¨èªã€‚
è«‹åƒè€ƒ YouTube ç•™è¨€èˆ‡ç¶²è·¯æµè¡Œç”¨å­—ï¼Œ
ä½ æ˜¯å°ˆæ¥­çš„ç¶²è·¯è©•è«–åˆ†æå¸«ï¼Œ
åˆ¤æ–·ä»¥ä¸‹ç•™è¨€æ˜¯å¦å¯èƒ½é€ æˆä»‡æ¨è¨€è«–ï¼ˆHate speechï¼‰ï¼Œ
åªå›è¦†ä¸€å€‹è©ï¼šæœƒã€ä¸æœƒã€‚
ç•™è¨€ï¼š{comment}
"""
 ```

3-1. Cyberbullying Detection Prompt (Label Accuracy:76%)
Provides contextual examples of sarcasm, group mockery, and verbal abuse, asking whether a comment qualifies as cyberbullying:
 ```python
prompt= f"""
ä½ æ˜¯ä¸€ä½ç†Ÿæ‚‰ç¤¾ç¾¤åª’é«”èˆ‡ç¶²è·¯æ–‡åŒ–çš„è©•è«–åˆ†æå¸«ã€‚

ç¶²è·¯éœ¸å‡Œæ˜¯æŒ‡é€éæ–‡å­—ã€èªæ°£ã€è¡¨æƒ…ã€è«·åˆºç­‰å½¢å¼ï¼Œåœ¨ç¶²è·¯ä¸Šæ”»æ“Šã€ç¾è¾±ã€
è²¶ä½ã€å­¤ç«‹ã€æ’æ“ æˆ–å˜²ç¬‘æŸäººã€‚é€™äº›è¨€è«–å¯èƒ½ä¸æ˜¯ç›´æ¥ç½µäººï¼Œ
å»ä»é€ æˆä»–äººæƒ…ç·’å‚·å®³ã€å¼•ç™¼å°ç‰¹å®šå€‹äººçš„æ•µæ„æˆ–ç¾¤é«”æ’æ“ ã€‚

- å†·å˜²ç†±è«·æˆ–èªå¸¶æ”»æ“Šï¼ˆä¾‹å¦‚ï¼šã€Œå¥½æ£’æ£’å–”ã€ã€ŒçœŸæœ‰ä½ çš„ï¼Œå‡ºä¾†ä¸Ÿè‡‰ã€ï¼‰
- è²¶ä½å¤–è²Œã€æ™ºå•†ã€è¡Œç‚ºï¼ˆä¾‹å¦‚ï¼šã€Œçœ‹ä»–é‚£å¾·è¡Œå°±çŸ¥é“äº†ã€ã€Œè…¦è¢‹æœ‰å•é¡Œå§ã€ï¼‰
- ä¾®è¾±ã€æ”»æ“Šã€ç¾¤å˜²ï¼ˆä¾‹å¦‚ï¼šã€Œä»–é€™ç¨®äººæ´»è©²è¢«ç½µã€ã€Œå¤§å®¶éƒ½çŸ¥é“ä»–å¾ˆçˆ›ã€ï¼‰
- ç”¨ç¬‘è©±æˆ–å˜²è«·èªæ°£æ©é£¾æ”»æ“Šæ„åœ–

è«‹æ ¹æ“šä¸Šè¿°å®šç¾©ï¼Œåˆ¤æ–·ä»¥ä¸‹ç•™è¨€æ˜¯å¦å±¬æ–¼ç¶²è·¯éœ¸å‡Œã€‚
è«‹åªå›ç­”ã€Œæœƒã€æˆ–ã€Œä¸æœƒã€ï¼Œä¸è¦è£œå……ç†ç”±æˆ–å…¶ä»–æ–‡å­—ã€‚

ç•™è¨€ï¼š
{comment}
"""
 ```

3-2 CyberBullying Detection Prompt without discription (Label Accuracy: 67%)
Model is asked to classify whether YouTube comments invovled cyberbullying content with the awareness of internet slang, tone and emoji and no context provided: 
 ```python
prompt= f"""
ä½ æ˜¯ä¸€ä½ç†Ÿæ‚‰ç¤¾ç¾¤åª’é«”èˆ‡ç¶²è·¯æ–‡åŒ–çš„è©•è«–åˆ†æå¸«ã€‚
è«‹åƒè€ƒ YouTube ç•™è¨€èˆ‡ç¶²è·¯ç”¨èªï¼Œä½ æ˜¯å°ˆæ¥­çš„ç¶²è·¯è©•è«–åˆ†æå¸«ï¼Œåˆ¤æ–·ä»¥ä¸‹ç•™è¨€æ˜¯å¦å¯èƒ½æ§‹æˆç¶²è·¯éœ¸å‡Œï¼ˆCyberbullyingï¼‰ï¼Œä¾‹å¦‚å†·å˜²ç†±è«·ã€ç¾¤é«”æ”»æ“Šã€ç¾è¾±æˆ–é€ æˆæƒ…ç·’å‚·å®³ã€‚åªå›è¦†ä¸€å€‹è©ï¼šã€Œæœƒã€æˆ–ã€Œä¸æœƒã€ã€‚
ç•™è¨€ï¼š{comment}
"""
 ```

### Step3: Structure Analysis Model


## File Structure

[Describe the file structure of your project, including how the files are organized and what each file contains. Be sure to explain the purpose of each file and how they are related to one another.]

## Analysis

[Describe your analysis methods and include any visualizations or graphics that you used to present your findings. Explain the insights that you gained from your analysis and how they relate to your research question or problem statement.]

## Results

Due to the low accuracy in detecting hatred, cyberbullying, and sentimental commentsâ€”initially yielding 34%, 67%, and 89% under evaluations involving mixed emotions and negative speechâ€”we shifted from intent-based labeling to sentiment-based labeling. Using prompts such as â€œYou are a professional comments analyst, please evaluate the following YouTube comments and identify hatred (cyberbullying and sentimental) content,â€ results remained inconsistent. Manual labeling allowed us to better differentiate among hateful, cyberbullying, and general sentiment comments. Importantly, not all negative comments contain cyberbullying elements; â€œsadâ€ comments, often non-aggressive, were filtered separately. Users were also reminded to clarify emotional expressions to avoid political misclassification. Additionally, we extracted 100 negative samples for manual relabeling, and after processing them with a large language model (LLM), accuracy improved to 89%.

## Contributors

| Avatar | Name | Role(s) |
|--------|------|---------|
| <img src="https://github.com/liangli-liu.png" width="40"/> | [æŸ³äº®åŠ› Liang-Li Liu](https://github.com/liangli-liu) | Project manager, program writer, analysis model structure |
| <img src="https://github.com/Changtzuan.png" width="40"/> | [å¼µå­å®‰ Andy Chang](https://github.com/Changtzuan) | Project manager, program writer, data collecting, data mining |
| <img src="https://github.com/Betty112510210.png" width="40"/> | [é™³éƒå®£ Yuhsuan Chen](https://github.com/Betty112510210) | Project manager, program writer, finetuning, presentation visualizer |


## Acknowledgments

We would like to express our sincere gratitude to **Professor Pien** for the invaluable guidance and support throughout the development of this project. His expertise greatly contributed to shaping our research direction and refining the design of our sentiment analysis framework.

We also acknowledge the use of the following resources:

- **YouTube Data API v3**, for providing access to public comment data used in our dataset.
- **OpenAI GPT-4o (via API access)**, for assisting in large-scale comment labelling and sentiment classification.


## References

This project was built using a variety of tools, libraries, and data sources:

### ğŸ§° Programming Languages & Libraries
- **Python** â€“ Main language for data collection, processing, and model development
- **Google API Client for Python** â€“ To access YouTube Data API v3
- **langdetect** â€“ For language identification
- **emoji** â€“ For emoji-preserving comment processing
- **OpenAI GPT-4o API** â€“ For comment labeling and LLM-based sentiment evaluation
- **R (dplyr)** â€“ Used during early stages for data wrangling and cleaning

### ğŸ“Š Data Sources
- **YouTube Comments** â€“ Collected via YouTube Data API v3  

### ğŸ§ª Analytical Methods
- **LLM Prompt Engineering** â€“ Comparing direct sentiment labeling with hate speech and cyberbullying contextual prompts
- **Manual vs. Automated Label Comparison** â€“ For accuracy benchmarking


